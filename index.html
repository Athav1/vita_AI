<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Inclusive AI App</title>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 0;
            padding: 0;
            background: #1a1a2e;
            color: #e6e6e6;
        }

        header {
            background: linear-gradient(to right, #0f2027, #203a43, #2c5364);
            color: #00d4ff;
            padding: 20px;
            text-align: center;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
            text-transform: uppercase;
            letter-spacing: 2px;
        }

        .container {
            max-width: 1200px;
            margin: auto;
            padding: 20px;
        }

        section {
            margin: 20px 0;
            padding: 20px;
            background: #21253a;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.5);
        }

        section h2 {
            color: #00ffab;
            font-size: 1.8rem;
        }

        .feature {
            margin: 15px 0;
        }

        .feature input,
        .feature button,
        .feature textarea {
            margin: 10px 0;
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #00d4ff;
            background: #2d3448;
            color: #e6e6e6;
            width: 100%;
            max-width: 400px;
        }

        button {
            background-color: #00d4ff;
            color: #1a1a2e;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }

        button:hover {
            background-color: #00ffab;
            transform: scale(1.05);
        }

        footer {
            text-align: center;
            padding: 15px;
            background: #0f2027;
            color: #00d4ff;
            font-size: 0.9rem;
        }

        .instructions {
            font-style: italic;
            color: #888;
            margin-top: 5px;
        }

    </style>
</head>

<body>
    <header>
        <h1>Inclusive AI App</h1>
        <p>Empowering Accessibility Through Technology</p>
    </header>

    <div class="container">
        <!-- Blind Users Section -->
        <section>
            <h2>For Blind Users</h2>
            <p>Upload an image to hear its description.</p>
            <div class="feature">
                <input type="file" id="imageUpload" accept="image/*" aria-label="Upload an image">
                <button onclick="analyzeImage()" aria-label="Analyze image">Analyze Image</button>
                <button onclick="stopAudio()" aria-label="Stop audio">Stop Audio</button>
                <p class="instructions">Upload a clear image for the best results.</p>
            </div>
            <p id="imageResponse"></p>
        </section>

        <!-- Deaf Users Section -->
        <section>
            <h2>For Deaf Users</h2>
            <p>Convert spoken language into text in real-time.</p>
            <div class="feature">
                <button onclick="startSpeechToText()" aria-label="Start speech-to-text">Start Speech-to-Text</button>
                <p id="speechOutput"></p>
            </div>
        </section>

        <!-- Mute Users Section -->
        <section>
            <h2>For Mute Users</h2>
            <p>Type your message, and let the app speak it for you.</p>
            <div class="feature">
                <textarea id="textInput" placeholder="Type your message here..." aria-label="Message input"></textarea>
                <button onclick="convertTextToSpeech()" aria-label="Speak message">Speak Message</button>
            </div>
        </section>
    </div>

    <footer>
        <p>&copy; 2024 Vita AI. Designed for accessibility and innovation.</p>
        <p>Created with dedication by <strong>Pratik Rajendra Nagargoje</strong>, <strong>Kalyani Balaraju Pucha</strong>, and <strong>Atharv Dattatray Damale</strong>.</p>
    </footer>

    <script>
        // Analyze Image for Blind Users using Google Cloud Vision API
        async function analyzeImage() {
            const fileInput = document.getElementById("imageUpload");
            const responseElement = document.getElementById("imageResponse");

            if (fileInput.files.length === 0) {
                responseElement.textContent = "Please upload an image.";
                speakText("Please upload an image.");
                return;
            }

            const file = fileInput.files[0];
            const reader = new FileReader();

            reader.onload = async function () {
                const base64Image = reader.result.split(",")[1];

                const requestBody = {
                    requests: [
                        {
                            image: { content: base64Image },
                            features: [{ type: "LABEL_DETECTION", maxResults: 10 }]
                        }
                    ]
                };

                const apiKey = "AIzaSyDqdgibUUSZEr22Nr01P4oZKYI9znHrGhM"; // Your API Key here
                const apiUrl = `https://vision.googleapis.com/v1/images:annotate?key=${apiKey}`;

                responseElement.textContent = "Processing image...";
                speakText("Processing image...");

                try {
                    const response = await fetch(apiUrl, {
                        method: "POST",
                        headers: {
                            "Content-Type": "application/json"
                        },
                        body: JSON.stringify(requestBody)
                    });

                    if (!response.ok) {
                        throw new Error("Failed to fetch image analysis. HTTP Status: " + response.status);
                    }

                    const data = await response.json();
                    console.log("API Response:", data);

                    if (data.responses[0].labelAnnotations && data.responses[0].labelAnnotations.length > 0) {
                        const labels = data.responses[0].labelAnnotations;

                        // Prepare a more descriptive sentence
                        let description = "This image contains ";

                        // Structure description based on the number of labels
                        if (labels.length > 1) {
                            description += labels.slice(0, -1).map(label => label.description).join(", ");
                            description += `, and ${labels[labels.length - 1].description}.`;
                        } else {
                            description += labels[0].description + ".";
                        }

                        // Make the description more readable
                        responseElement.textContent = description;
                        speakText(description);
                    } else {
                        throw new Error("No description available. Try uploading a clearer image.");
                    }
                } catch (error) {
                    console.error("Error during image processing:", error);
                    responseElement.textContent = error.message;
                    speakText(error.message);
                }
            };

            reader.readAsDataURL(file);
        }

        // Stop Audio for Blind Users
        function stopAudio() {
            window.speechSynthesis.cancel();
        }

        // Start Speech-to-Text for Deaf Users
        function startSpeechToText() {
            const outputElement = document.getElementById("speechOutput");
            const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = "en-US";
            recognition.interimResults = false;
            recognition.start();

            recognition.onresult = (event) => {
                outputElement.textContent = event.results[0][0].transcript;
            };

            recognition.onerror = (event) => {
                outputElement.textContent = `Speech recognition error: ${event.error}`;
            };
        }

        // Text-to-Speech for Mute Users
        function convertTextToSpeech() {
            const text = document.getElementById("textInput").value.trim();
            if (!text) {
                alert("Please enter some text.");
                return;
            }

            const synth = window.speechSynthesis;
            const utterance = new SpeechSynthesisUtterance(text);
            synth.speak(utterance);
        }

        // Speak Text for Blind Users
        function speakText(text) {
            const synth = window.speechSynthesis;
            const utterance = new SpeechSynthesisUtterance(text);
            synth.speak(utterance);
        }
    </script>
<script src="https://www.gstatic.com/dialogflow-console/fast/messenger/bootstrap.js?v=1"></script>
<df-messenger
  chat-icon="https:&#x2F;&#x2F;image.similarpng.com&#x2F;very-thumbnail&#x2F;2021&#x2F;05&#x2F;Colorful-circle-logo-design-illustration-on-transparent-background-PNG.png"
  chat-title="VitalAI"
  agent-id="66defd9c-f98f-4d8d-999b-c167890813f2"
  language-code="en"
></df-messenger>
</body>

</html>

